{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9187be37",
   "metadata": {},
   "source": [
    "# Pré-processamento de Textos em NLP\n",
    "\n",
    "Este notebook realiza o pré-processamento de dois textos distintos:\n",
    "1. **Matéria jornalística** do jornal A Tribuna\n",
    "2. **Bula do medicamento** Doril\n",
    "\n",
    "## Etapas do Pré-processamento:\n",
    "1. Remover tags HTML\n",
    "2. Remover URLs\n",
    "3. Remover emojis\n",
    "4. Remover stopwords\n",
    "5. Remover sinais de pontuação\n",
    "6. Remover caracteres especiais\n",
    "7. Remover espaços em branco excedentes\n",
    "8. Substituir palavras de chat por formas normais\n",
    "9. Converter números em palavras\n",
    "10. Converter para letras minúsculas\n",
    "11. Aplicar correção ortográfica\n",
    "12. Aplicar stemização\n",
    "13. Aplicar lematização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3328aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pt-core-news-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-3.8.0/pt_core_news_sm-3.8.0-py3-none-any.whl (13.0 MB)\n",
      "     ---------------------------------------- 0.0/13.0 MB ? eta -:--:--\n",
      "     --- ------------------------------------ 1.0/13.0 MB 5.0 MB/s eta 0:00:03\n",
      "     -------- ------------------------------- 2.6/13.0 MB 6.0 MB/s eta 0:00:02\n",
      "     ---------- ----------------------------- 3.4/13.0 MB 5.0 MB/s eta 0:00:02\n",
      "     ------------- -------------------------- 4.5/13.0 MB 5.1 MB/s eta 0:00:02\n",
      "     ---------------- ----------------------- 5.5/13.0 MB 5.2 MB/s eta 0:00:02\n",
      "     -------------------- ------------------- 6.6/13.0 MB 5.2 MB/s eta 0:00:02\n",
      "     ----------------------- ---------------- 7.6/13.0 MB 5.2 MB/s eta 0:00:02\n",
      "     --------------------------- ------------ 8.9/13.0 MB 5.1 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 10.0/13.0 MB 5.2 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 11.0/13.0 MB 5.1 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 11.8/13.0 MB 5.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 13.0/13.0 MB 5.0 MB/s  0:00:02\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('pt_core_news_sm')\n"
     ]
    }
   ],
   "source": [
    "# Instalação das bibliotecas necessárias\n",
    "!pip install nltk spacy emoji pyspellchecker num2words beautifulsoup4\n",
    "!python -m spacy download pt_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a745700d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\helio\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\helio\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\helio\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package rslp to\n",
      "[nltk_data]     C:\\Users\\helio\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package rslp is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bibliotecas carregadas com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# Importação das bibliotecas\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "import spacy\n",
    "import emoji\n",
    "from spellchecker import SpellChecker\n",
    "from num2words import num2words\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import RSLPStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Downloads necessários do NLTK\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('rslp')\n",
    "\n",
    "# Carregando modelo do spaCy para português\n",
    "nlp = spacy.load('pt_core_news_sm')\n",
    "\n",
    "print(\"Bibliotecas carregadas com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "13fa80d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TEXTO ORIGINAL - BULA DORIL ===\n",
      "Tamanho: 13742 caracteres\n",
      "DORIL®\n",
      "(ácido acetilsalicílico + cafeína)\n",
      "\n",
      "Cosmed Indústria de Cosméticos e Medicamentos S.A.\n",
      "\n",
      "Comprimido\n",
      "\n",
      "500mg + 30mg\n",
      "\n",
      "\fI - IDENTIFICAÇÃO DO MEDICAMENTO:\n",
      "Doril®\n",
      "ácido acetilsalicílico + cafeína\n",
      "APRESENTAÇÕES\n",
      "Comprimido.\n",
      "Embalagens contendo 20 ou 150 comprimidos.\n",
      "VIA DE ADMINISTRAÇÃO: ORAL\n",
      "USO ADULTO\n",
      "COMPOSIÇÃO\n",
      "Cada comprimido contém:\n",
      "ácido acetilsalicílico …………………………………………………….................................... 500mg\n",
      "cafeína ………………………………….................……………………………….…...…............ 30mg\n",
      "ex...\n",
      "\n",
      "=== TEXTO ORIGINAL - JORNAL A TRIBUNA ===\n",
      "Tamanho: 2634 caracteres\n",
      "VITÓRIA-ES | DOMINGO, 14 DE JANEIRO DE 2018 | ANO LXXIX | Nº 26.236 | FUNDADO EM 22/09/1938 | EDIÇÃO DE 72 PÁGINAS Vo c ê conhece bem seus amigos? >AT 2 THIAGO COUTINHO/AT THIAGO COUTINHO/AT R$ 3,50 DEMAIS CIDADES R$ 3 ,0 0 GRANDE VITÓRIA AS S I N E 3323 -6333 Transexuais querem fazer parte da cota feminina nas próximas eleições >32 R efúgios ro m â n t i c o s no Estado >14 e 15 Cupom para concorrer a R$ 500 em compras >13 PPPaaaiiisss   pppeeedddeeemmm   aaajjjuuudddaaa   aaa mmmééédddiiicccoo...\n"
     ]
    }
   ],
   "source": [
    "# Carregamento dos textos originais\n",
    "with open('doril.txt', 'r', encoding='utf-8') as f:\n",
    "    texto_doril = f.read()\n",
    "\n",
    "with open('no14011801.txt', 'r', encoding='utf-8') as f:\n",
    "    texto_jornal = f.read()\n",
    "\n",
    "print(\"=== TEXTO ORIGINAL - BULA DORIL ===\")\n",
    "print(f\"Tamanho: {len(texto_doril)} caracteres\")\n",
    "print(texto_doril[:500] + \"...\\n\")\n",
    "\n",
    "print(\"=== TEXTO ORIGINAL - JORNAL A TRIBUNA ===\")\n",
    "print(f\"Tamanho: {len(texto_jornal)} caracteres\")\n",
    "print(texto_jornal[:500] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bcbc6bb",
   "metadata": {},
   "source": [
    "## Definição das Funções de Pré-processamento\n",
    "\n",
    "Cada função implementa uma etapa específica do pré-processamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3cc6ada7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Funções 1-4 definidas!\n"
     ]
    }
   ],
   "source": [
    "# Etapa 1: Remover tags HTML\n",
    "def step_1_remove_html_tags(text):\n",
    "    \"\"\"Remove tags HTML do texto\"\"\"\n",
    "    soup = BeautifulSoup(text, 'html.parser')\n",
    "    return soup.get_text()\n",
    "\n",
    "# Etapa 2: Remover URLs\n",
    "def step_2_remove_urls(text):\n",
    "    \"\"\"Remove URLs do texto\"\"\"\n",
    "    url_pattern = re.compile(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
    "    text = url_pattern.sub('', text)\n",
    "    # Remove também URLs simplificadas como t.co/...\n",
    "    text = re.sub(r'\\S*\\.co/\\S*', '', text)\n",
    "    text = re.sub(r'www\\.\\S+', '', text)\n",
    "    return text\n",
    "\n",
    "# Etapa 3: Remover emojis\n",
    "def step_3_remove_emojis(text):\n",
    "    \"\"\"Remove emojis do texto\"\"\"\n",
    "    return emoji.replace_emoji(text, replace='')\n",
    "\n",
    "# Etapa 4: Remover stopwords\n",
    "def step_4_remove_stopwords(text):\n",
    "    \"\"\"Remove stopwords em português\"\"\"\n",
    "    stop_words = set(stopwords.words('portuguese'))\n",
    "    # Adicionar algumas stopwords customizadas\n",
    "    stop_words.update(['que', 'de', 'a', 'o', 'e', 'do', 'da', 'em', 'um', 'para', 'é', 'com', 'não', 'uma', 'os', 'no', 'se', 'na', 'por', 'mais', 'as', 'dos', 'como', 'mas', 'foi', 'ao', 'ele', 'das', 'tem', 'à', 'seu', 'sua', 'ou', 'ser', 'quando', 'muito', 'há', 'nos', 'já', 'está', 'eu', 'também', 'só', 'pelo', 'pela', 'até', 'isso', 'ela', 'entre', 'era', 'depois', 'sem', 'mesmo', 'aos', 'ter', 'seus', 'suas', 'numa', 'nem', 'suas', 'meu', 'às', 'minha', 'têm', 'numa', 'pelos', 'pelas', 'essa', 'num', 'essa', 'foram', 'eles', 'estas', 'tinha', 'outro', 'essa', 'esses'])\n",
    "    \n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "print(\"Funções 1-4 definidas!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e0e05754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Funções 5-8 definidas e melhoradas!\n"
     ]
    }
   ],
   "source": [
    "# Etapa 5: Remover sinais de pontuação\n",
    "def step_5_remove_punctuation(text):\n",
    "    \"\"\"Remove sinais de pontuação\"\"\"\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    return text.translate(translator)\n",
    "\n",
    "# Etapa 6: Remover caracteres especiais (MELHORADA)\n",
    "def step_6_remove_special_chars(text):\n",
    "    \"\"\"Remove caracteres especiais e normaliza repetições excessivas de letras\"\"\"\n",
    "    # Primeiro, normaliza repetições excessivas de letras (mais de 2 iguais seguidas)\n",
    "    # \"PPPaaaiiisss\" -> \"PPaaiiss\", \"mmmééédddiiicccooosss\" -> \"mmééddiiccoos\"\n",
    "    text = re.sub(r'(.)\\1{2,}', r'\\1\\1', text)\n",
    "    \n",
    "    # Remove caracteres especiais, mantendo apenas letras, números e espaços\n",
    "    text = re.sub(r'[^a-zA-ZÀ-ÿ0-9\\s]', '', text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Etapa 7: Remover espaços excedentes\n",
    "def step_7_remove_extra_spaces(text):\n",
    "    \"\"\"Remove espaços em branco excedentes\"\"\"\n",
    "    return re.sub(r'\\s+', ' ', text.strip())\n",
    "\n",
    "# Etapa 8: Substituir palavras de chat (MELHORADA)\n",
    "def step_8_normalize_chat_words(text):\n",
    "    \"\"\"Substitui abreviações e gírias por formas normais, incluindo palavras com repetições\"\"\"\n",
    "    chat_dict = {\n",
    "        'vc': 'você',\n",
    "        'vcs': 'vocês',\n",
    "        'tb': 'também',\n",
    "        'tmbm': 'também',\n",
    "        'pq': 'porque',\n",
    "        'qq': 'qualquer',\n",
    "        'qdo': 'quando',\n",
    "        'ñ': 'não',\n",
    "        'nao': 'não',\n",
    "        'naoo': 'não',\n",
    "        'naaoo': 'não',\n",
    "        'kk': '',\n",
    "        'kkk': '',\n",
    "        'kkkk': '',\n",
    "        'rs': '',\n",
    "        'rsrs': '',\n",
    "        'haha': '',\n",
    "        'hehe': '',\n",
    "        'blz': 'beleza',\n",
    "        'flw': 'falou',\n",
    "        'cmg': 'comigo',\n",
    "        'ctg': 'contigo',\n",
    "        'mt': 'muito',\n",
    "        'mto': 'muito',\n",
    "        'msm': 'mesmo',\n",
    "        'td': 'tudo',\n",
    "        'tds': 'todos',\n",
    "        'bjo': 'beijo',\n",
    "        'bjs': 'beijos',\n",
    "        # Adiciona tratamento para palavras com repetições que sabemos que são comuns\n",
    "        'sleepy': 'com sono',\n",
    "        'sleeepy': 'com sono',\n",
    "        'sleeeepy': 'com sono',\n",
    "        'sleeeeepy': 'com sono'\n",
    "    }\n",
    "    \n",
    "    words = text.split()\n",
    "    normalized_words = []\n",
    "    \n",
    "    for word in words:\n",
    "        word_lower = word.lower()\n",
    "        \n",
    "        # Verifica se a palavra está no dicionário diretamente\n",
    "        if word_lower in chat_dict:\n",
    "            replacement = chat_dict[word_lower]\n",
    "            if replacement:  # Se não for string vazia\n",
    "                normalized_words.append(replacement)\n",
    "        else:\n",
    "            # Tenta normalizar repetições antes de verificar o dicionário\n",
    "            normalized_word = re.sub(r'(.)\\1{2,}', r'\\1', word_lower)\n",
    "            if normalized_word in chat_dict:\n",
    "                replacement = chat_dict[normalized_word]\n",
    "                if replacement:  # Se não for string vazia\n",
    "                    normalized_words.append(replacement)\n",
    "            else:\n",
    "                normalized_words.append(word)\n",
    "    \n",
    "    return ' '.join(normalized_words)\n",
    "\n",
    "print(\"Funções 5-8 definidas e melhoradas!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a8102f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Funções 9-11 definidas e melhoradas!\n"
     ]
    }
   ],
   "source": [
    "# Etapa 9: Converter números em palavras (CORRIGIDA COMPLETAMENTE)\n",
    "def step_9_convert_numbers_to_words(text):\n",
    "    \"\"\"Converte TODOS os números em palavras, incluindo números grandes e datas\"\"\"\n",
    "    def replace_number(match):\n",
    "        number = match.group()\n",
    "        try:\n",
    "            # Tenta converter para inteiro primeiro\n",
    "            num = int(number)\n",
    "            \n",
    "            # Para números muito grandes (como datas), divide em partes menores\n",
    "            if num > 100000:\n",
    "                # Se parece com uma data, trata especialmente\n",
    "                if len(number) == 8:\n",
    "                    # Formato DDMMAAAA - divide em partes\n",
    "                    day = int(number[:2])\n",
    "                    month = int(number[2:4])\n",
    "                    year = int(number[4:])\n",
    "                    \n",
    "                    day_words = num2words(day, lang='pt') if day <= 31 else num2words(day, lang='pt')\n",
    "                    month_words = num2words(month, lang='pt') if month <= 12 else num2words(month, lang='pt')\n",
    "                    year_words = num2words(year, lang='pt') if year <= 2100 else num2words(year, lang='pt')\n",
    "                    \n",
    "                    return f\"{day_words} {month_words} {year_words}\"\n",
    "                else:\n",
    "                    # Para outros números grandes, converte normalmente\n",
    "                    return num2words(num, lang='pt')\n",
    "            else:\n",
    "                # Números normais - SEMPRE converte\n",
    "                return num2words(num, lang='pt')\n",
    "                \n",
    "        except:\n",
    "            try:\n",
    "                # Tenta converter para float\n",
    "                num = float(number)\n",
    "                return num2words(int(num), lang='pt')  # Converte float para int primeiro\n",
    "            except:\n",
    "                return number\n",
    "    \n",
    "    # Encontra TODOS os números\n",
    "    # Primeiro, converte números isolados\n",
    "    text = re.sub(r'\\b\\d+(?:\\.\\d+)?\\b', replace_number, text)\n",
    "    \n",
    "    # Remove números de nomes de usuário/tags mantendo o texto\n",
    "    text = re.sub(r'(\\w+)\\d+', r'\\1', text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Etapa 10: Converter para minúsculas\n",
    "def step_10_to_lowercase(text):\n",
    "    \"\"\"Converte todo o texto para minúsculas\"\"\"\n",
    "    return text.lower()\n",
    "\n",
    "# Etapa 11: Correção ortográfica (MELHORADA)\n",
    "def step_11_spell_correction(text):\n",
    "    \"\"\"Aplica correção ortográfica melhorada para tratar repetições\"\"\"\n",
    "    spell = SpellChecker(language='pt')\n",
    "    words = text.split()\n",
    "    corrected_words = []\n",
    "    \n",
    "    for word in words:\n",
    "        if len(word) > 2:  # Só corrige palavras com mais de 2 caracteres\n",
    "            \n",
    "            # Primeiro, normaliza repetições excessivas na palavra\n",
    "            normalized_word = re.sub(r'(.)\\1{2,}', r'\\1', word.lower())\n",
    "            \n",
    "            # Verifica se a palavra normalizada está no dicionário\n",
    "            if normalized_word in spell:\n",
    "                corrected_words.append(normalized_word)\n",
    "            else:\n",
    "                # Tenta corrigir a palavra normalizada\n",
    "                correction = spell.correction(normalized_word)\n",
    "                if correction and correction != normalized_word:\n",
    "                    corrected_words.append(correction)\n",
    "                else:\n",
    "                    # Se não conseguiu corrigir, tenta algumas normalizações comuns\n",
    "                    # Remove todas as repetições deixando apenas uma letra\n",
    "                    single_char_word = re.sub(r'(.)\\1+', r'\\1', word.lower())\n",
    "                    if single_char_word in spell:\n",
    "                        corrected_words.append(single_char_word)\n",
    "                    else:\n",
    "                        single_correction = spell.correction(single_char_word)\n",
    "                        if single_correction and single_correction != single_char_word:\n",
    "                            corrected_words.append(single_correction)\n",
    "                        else:\n",
    "                            # Se ainda não conseguiu, mantém a palavra original normalizada\n",
    "                            corrected_words.append(normalized_word)\n",
    "        else:\n",
    "            corrected_words.append(word)\n",
    "    \n",
    "    return ' '.join(corrected_words)\n",
    "\n",
    "print(\"Funções 9-11 definidas e melhoradas!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "42a4d7ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Funções 12-13 definidas!\n",
      "\n",
      "Todas as funções de pré-processamento foram definidas com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# Etapa 12: Stemização\n",
    "def step_12_stemming(text):\n",
    "    \"\"\"Aplica stemização usando RSLP Stemmer\"\"\"\n",
    "    stemmer = RSLPStemmer()\n",
    "    words = text.split()\n",
    "    stemmed_words = [stemmer.stem(word) for word in words]\n",
    "    return ' '.join(stemmed_words)\n",
    "\n",
    "# Etapa 13: Lematização \n",
    "def step_13_lemmatization(text):\n",
    "    \"\"\"Aplica lematização usando spaCy, com tratamento especial para palavras stemizadas\"\"\"\n",
    "    \n",
    "    # Dicionário para corrigir palavras comuns que ficaram stemizadas\n",
    "    stem_to_lemma = {\n",
    "        # Números\n",
    "        'vint': 'vinte', 'trint': 'trinta', 'quarent': 'quarenta', 'cinquent': 'cinquenta',\n",
    "        'catorz': 'catorze', 'quinz': 'quinze', 'doiz': 'doze', 'trez': 'treze', \n",
    "        'dezoitr': 'dezoito', 'seil': 'seis', 'oit': 'oito', 'quatr': 'quatro',\n",
    "        'cinc': 'cinco', 'nov': 'nove', 'set': 'sete', 'trê': 'três',\n",
    "        \n",
    "        # Termos médicos (específicos da bula)\n",
    "        'medic': 'médico', 'comprim': 'comprimido', 'ácid': 'ácido', 'analgés': 'analgésico',\n",
    "        'antipoé': 'antipirético', 'func': 'funcionar', 'contraindic': 'contraindicado',\n",
    "        'paci': 'paciente', 'administr': 'administrar', 'oral': 'oral', 'adult': 'adulto',\n",
    "        'compo': 'composição', 'cad': 'cada', 'contémr': 'contém', 'excipir': 'excipiente',\n",
    "        'amid': 'amido', 'cor': 'cor', 'vermelh': 'vermelho', 'bul': 'bula',\n",
    "        'inforr': 'informar', 'indic': 'indicado', 'espec': 'especial', 'trat': 'tratar',\n",
    "        'reduç': 'redução', 'febr': 'febre', 'cabeç': 'cabeça', 'açã': 'ação',\n",
    "        'antipiré': 'antipirético', 'portant': 'portanto', 'atu': 'atuar', 'alivi': 'aliviar',\n",
    "        'possur': 'possuir', 'subst': 'substância', 'potencializ': 'potencializar',\n",
    "        'apresent': 'apresentar', 'aind': 'ainda', 'efeit': 'efeito', 'estimul': 'estimular',\n",
    "        'hum': 'humano', 'est': 'estar', 'alert': 'alerta', 'atenç': 'atenção',\n",
    "        'promov': 'promover', 'constr': 'constrição', 'diminu': 'diminuir', 'calibr': 'calibre',\n",
    "        'sanguíne': 'sanguíneo', 'cérebrr': 'cerebral', 'pod': 'poder', 'contribu': 'contribuir',\n",
    "        'dev': 'dever', 'us': 'usar', 'hipersensibil': 'hipersensibilidade', 'outr': 'outro',\n",
    "        'salicilat': 'salicilato', 'qualqu': 'qualquer', 'compon': 'componente', 'fórmul': 'fórmula',\n",
    "        'produt': 'produto', 'predispostr': 'predisposto', 'dispeps': 'dispepsia', 'indigest': 'indigestão',\n",
    "        'sab': 'saber', 'portr': 'portar', 'algum': 'algum', 'Les': 'lesão', 'muco': 'mucosa',\n",
    "        'gástr': 'gástrica', 'úlc': 'úlcera', 'intoler': 'intolerância', 'hepá': 'hepática',\n",
    "        'grav': 'grave', 'além': 'além', 'hemofíl': 'hemofilia', 'problem': 'problema',\n",
    "        'sangrent': 'sangramento', 'tom': 'tomar', 'cuid': 'cuidado', 'renal': 'renal',\n",
    "        'compromet': 'comprometida', 'Prim': 'primeiro', 'mes': 'mês', 'Gravid': 'gravidez',\n",
    "        'após': 'após', 'períod': 'período', 'empreg': 'emprego', 'ca': 'caso', 'absolut': 'absoluto',\n",
    "        \n",
    "        # Profissões e substantivos\n",
    "        'ministr': 'ministro', 'presid': 'presidente', 'pilot': 'piloto', 'líd': 'líder', 'chef': 'chefe',\n",
    "        \n",
    "        # Palavras comuns\n",
    "        'famíl': 'família', 'empr': 'empresa', 'cidad': 'cidade', 'pesso': 'pessoa',\n",
    "        'part': 'parte', 'grand': 'grande', 'feminin': 'feminino', 'próx': 'próximo',\n",
    "        'refúgi': 'refúgio', 'amig': 'amigo', 'fund': 'fundar', 'ediç': 'edição', \n",
    "        'págin': 'página', 'comiss': 'comissão', 'públic': 'público', 'film': 'filme',\n",
    "        'parc': 'parque', 'especi': 'especial', 'dilem': 'dilema', 'carg': 'cargo',\n",
    "        'ritm': 'ritmo', 'internac': 'internacional', 'relatóri': 'relatório',\n",
    "        'sobr': 'sobre', 'fest': 'festa', 'liberdadr': 'liberdade',\n",
    "        \n",
    "        # Verbos\n",
    "        'conhec': 'conhecer', 'gost': 'gostar', 'ach': 'achar', 'trabalh': 'trabalhar',\n",
    "        'represent': 'representar', 'imagin': 'imaginar', 'aprend': 'aprender', \n",
    "        'pergunt': 'perguntar', 'concorr': 'concorrer', 'compr': 'comprar',\n",
    "        'ajud': 'ajudar', 'deix': 'deixar', 'conver': 'conversar',\n",
    "        'pression': 'pressionar', 'investig': 'investigar', 'coloc': 'colocar',\n",
    "        'desej': 'desejar', 'divulg': 'divulgar', 'pass': 'passar', 'cadastr': 'cadastrar',\n",
    "        'apaixon': 'apaixonar', 'entr': 'entrar', 'entrr': 'entrar',\n",
    "        \n",
    "        # Adjetivos e outros\n",
    "        'vici': 'viciado', 'depend': 'dependente', 'gov': 'governo', 'decis': 'decisão',\n",
    "        'risc': 'risco', 'vergonh': 'vergonha', 'aul': 'aula', 'famili': 'família'\n",
    "    }\n",
    "    \n",
    "    words = text.split()\n",
    "    lemmatized_words = []\n",
    "    \n",
    "    for word in words:\n",
    "        # Primeiro verifica se a palavra stemizada tem correção no dicionário\n",
    "        if word.lower() in stem_to_lemma:\n",
    "            lemmatized_words.append(stem_to_lemma[word.lower()])\n",
    "        else:\n",
    "            # Tenta aplicar lematização normal com spaCy\n",
    "            try:\n",
    "                doc = nlp(word)\n",
    "                if len(doc) > 0 and doc[0].lemma_ != word and doc[0].lemma_ != '-PRON-':\n",
    "                    lemmatized_words.append(doc[0].lemma_)\n",
    "                else:\n",
    "                    \n",
    "                    best_word = word\n",
    "                    for suffix in ['', 'a', 'o', 'e', 'ar', 'er', 'ir', 'ão']:\n",
    "                        test_word = word + suffix\n",
    "                        try:\n",
    "                            test_doc = nlp(test_word)\n",
    "                            if len(test_doc) > 0 and test_doc[0].is_alpha and not test_doc[0].is_oov:\n",
    "                                lemma = test_doc[0].lemma_\n",
    "                                if lemma != '-PRON-' and len(lemma) > 2:\n",
    "                                    best_word = lemma\n",
    "                                    break\n",
    "                        except:\n",
    "                            continue\n",
    "                    lemmatized_words.append(best_word)\n",
    "            except:\n",
    "                lemmatized_words.append(word)\n",
    "    \n",
    "    return ' '.join(lemmatized_words)\n",
    "\n",
    "print(\"Funções 12-13 definidas!\")\n",
    "print(\"\\nTodas as funções de pré-processamento foram definidas com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "be2a3c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TESTE DA LEMATIZAÇÃO MELHORADA ===\n",
      "Texto stemizado: vint trint catorz médic famíl conhec gost fazer trabalh gov ministr represent\n",
      "Após lematização: vinte trinta catorze Médic família conhecer gostar fazer trabalhar governo ministro representar\n",
      "\n",
      "=== COMPARAÇÃO PALAVRA POR PALAVRA ===\n",
      " 1. vint       -> vinte\n",
      " 2. trint      -> trinta\n",
      " 3. catorz     -> catorze\n",
      " 4. médic      -> Médic\n",
      " 5. famíl      -> família\n",
      " 6. conhec     -> conhecer\n",
      " 7. gost       -> gostar\n",
      " 8. fazer      -> fazer\n",
      " 9. trabalh    -> trabalhar\n",
      "10. gov        -> governo\n",
      "11. ministr    -> ministro\n",
      "12. represent  -> representar\n",
      "\n",
      "✅ Teste da lematização concluído!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"=== TESTE DA LEMATIZAÇÃO MELHORADA ===\")\n",
    "\n",
    "\n",
    "texto_stemizado = \"vint trint catorz médic famíl conhec gost fazer trabalh gov ministr represent\"\n",
    "print(f\"Texto stemizado: {texto_stemizado}\")\n",
    "\n",
    "\n",
    "resultado_lemmatizado = step_13_lemmatization(texto_stemizado)\n",
    "print(f\"Após lematização: {resultado_lemmatizado}\")\n",
    "\n",
    "print(\"\\n=== COMPARAÇÃO PALAVRA POR PALAVRA ===\")\n",
    "palavras_stem = texto_stemizado.split()\n",
    "palavras_lemma = resultado_lemmatizado.split()\n",
    "\n",
    "for i, (stem, lemma) in enumerate(zip(palavras_stem, palavras_lemma)):\n",
    "    print(f\"{i+1:2d}. {stem:10} -> {lemma}\")\n",
    "\n",
    "print(\"\\n✅ Teste da lematização concluído!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4700cbb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TESTE DA CONVERSÃO DE NÚMEROS ===\n",
      "Texto original: 22091938 fundação em 1998 nickcristan17 500 reais\n",
      "Após conversão: vinte e dois nove mil novecentos e trinta e oito fundação em mil novecentos e noventa e oito nickcristan1 quinhentos reais\n",
      "\n",
      "=== TESTE COM MAIS PALAVRAS STEMIZADAS ===\n",
      "Texto stemizado: seil oit quatr cinc nov set entrr liberdadr empr divulg\n",
      "Após lematização: seis oito quatro cinco nove sete entrar liberdade empresa divulgar\n",
      "\n",
      "✅ Testes concluídos!\n"
     ]
    }
   ],
   "source": [
    "# Teste da conversão de números melhorada\n",
    "print(\"=== TESTE DA CONVERSÃO DE NÚMEROS ===\")\n",
    "\n",
    "texto_com_numeros = \"22091938 fundação em 1998 nickcristan17 500 reais\"\n",
    "print(f\"Texto original: {texto_com_numeros}\")\n",
    "\n",
    "resultado_numeros = step_9_convert_numbers_to_words(texto_com_numeros)\n",
    "print(f\"Após conversão: {resultado_numeros}\")\n",
    "\n",
    "print(\"\\n=== TESTE COM MAIS PALAVRAS STEMIZADAS ===\")\n",
    "texto_stem_completo = \"seil oit quatr cinc nov set entrr liberdadr empr divulg\"\n",
    "print(f\"Texto stemizado: {texto_stem_completo}\")\n",
    "\n",
    "resultado_lemma_completo = step_13_lemmatization(texto_stem_completo)\n",
    "print(f\"Após lematização: {resultado_lemma_completo}\")\n",
    "\n",
    "print(\"\\n✅ Testes concluídos!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91cf78d2",
   "metadata": {},
   "source": [
    "## Aplicação Sequencial do Pré-processamento\n",
    "\n",
    "Agora vamos aplicar todas as etapas sequencialmente e mostrar o resultado após cada transformação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9df657f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TESTE DAS MELHORIAS ===\n",
      "Texto original:\n",
      "PPPaaaiiisss pppeeedddeeemmm aaajjjuuudddaaa aaa mmmééédddiiicccooosss pppaaarrraaa tttrrraaatttaaarrr fffiiilllhhhooosss vvviiiccciiiaaadddooosss\n",
      "\n",
      "Após etapa 6 (remover caracteres especiais):\n",
      "PPaaiiss ppeeddeemm aajjuuddaa aa mmééddiiccooss ppaarraa ttrraattaarr ffiillhhooss vviicciiaaddooss\n",
      "\n",
      "Após etapa 8 (normalizar chat):\n",
      "PPaaiiss ppeeddeemm aajjuuddaa aa mmééddiiccooss ppaarraa ttrraattaarr ffiillhhooss vviicciiaaddooss\n",
      "\n",
      "Após etapa 10 (minúsculas):\n",
      "ppaaiiss ppeeddeemm aajjuuddaa aa mmééddiiccooss ppaarraa ttrraattaarr ffiillhhooss vviicciiaaddooss\n",
      "\n",
      "Após etapa 11 (correção ortográfica):\n",
      "pais pedem ajuda aa médicos para tratar filhos viciados\n",
      "\n",
      "==================================================\n",
      "pais pedem ajuda aa médicos para tratar filhos viciados\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Teste das melhorias com o texto problemático\n",
    "texto_teste = \"PPPaaaiiisss pppeeedddeeemmm aaajjjuuudddaaa aaa mmmééédddiiicccooosss pppaaarrraaa tttrrraaatttaaarrr fffiiilllhhhooosss vvviiiccciiiaaadddooosss\"\n",
    "\n",
    "print(\"=== TESTE DAS MELHORIAS ===\")\n",
    "print(f\"Texto original:\\n{texto_teste}\")\n",
    "\n",
    "print(f\"\\nApós etapa 6 (remover caracteres especiais):\")\n",
    "teste_etapa6 = step_6_remove_special_chars(texto_teste)\n",
    "print(teste_etapa6)\n",
    "\n",
    "print(f\"\\nApós etapa 8 (normalizar chat):\")\n",
    "teste_etapa8 = step_8_normalize_chat_words(teste_etapa6)\n",
    "print(teste_etapa8)\n",
    "\n",
    "print(f\"\\nApós etapa 10 (minúsculas):\")\n",
    "teste_etapa10 = step_10_to_lowercase(teste_etapa8)\n",
    "print(teste_etapa10)\n",
    "\n",
    "print(f\"\\nApós etapa 11 (correção ortográfica):\")\n",
    "teste_etapa11 = step_11_spell_correction(teste_etapa10)\n",
    "print(teste_etapa11)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3f1992a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Função de aplicação sequencial definida!\n"
     ]
    }
   ],
   "source": [
    "def apply_preprocessing_steps(text, text_name):\n",
    "    \"\"\"Aplica todas as etapas de pré-processamento sequencialmente\"\"\"\n",
    "    \n",
    "    steps = [\n",
    "        (\"Original\", lambda x: x),\n",
    "        (\"1. Remover HTML\", step_1_remove_html_tags),\n",
    "        (\"2. Remover URLs\", step_2_remove_urls),\n",
    "        (\"3. Remover emojis\", step_3_remove_emojis),\n",
    "        (\"4. Remover stopwords\", step_4_remove_stopwords),\n",
    "        (\"5. Remover pontuação\", step_5_remove_punctuation),\n",
    "        (\"6. Remover caracteres especiais\", step_6_remove_special_chars),\n",
    "        (\"7. Remover espaços excedentes\", step_7_remove_extra_spaces),\n",
    "        (\"8. Normalizar palavras de chat\", step_8_normalize_chat_words),\n",
    "        (\"9. Converter números\", step_9_convert_numbers_to_words),\n",
    "        (\"10. Converter para minúsculas\", step_10_to_lowercase),\n",
    "        (\"11. Correção ortográfica\", step_11_spell_correction),\n",
    "        (\"12. Stemização\", step_12_stemming),\n",
    "        (\"13. Lematização\", step_13_lemmatization)\n",
    "    ]\n",
    "    \n",
    "    current_text = text\n",
    "    results = {}\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"PRÉ-PROCESSAMENTO: {text_name.upper()}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    for step_name, step_function in steps:\n",
    "        if step_name != \"Original\":\n",
    "            current_text = step_function(current_text)\n",
    "        \n",
    "        results[step_name] = current_text\n",
    "        \n",
    "        print(f\"\\n{'-'*40}\")\n",
    "        print(f\"ETAPA: {step_name}\")\n",
    "        print(f\"{'-'*40}\")\n",
    "        print(f\"Tamanho: {len(current_text)} caracteres\")\n",
    "        print(f\"Palavras: {len(current_text.split())} palavras\")\n",
    "        \n",
    "        # Mostra uma amostra do texto (primeiros 300 caracteres)\n",
    "        sample = current_text[:300] + \"...\" if len(current_text) > 300 else current_text\n",
    "        print(f\"Amostra: {sample}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"Função de aplicação sequencial definida!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3ffba6f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "PRÉ-PROCESSAMENTO: BULA DO DORIL\n",
      "============================================================\n",
      "\n",
      "----------------------------------------\n",
      "ETAPA: Original\n",
      "----------------------------------------\n",
      "Tamanho: 13742 caracteres\n",
      "Palavras: 1955 palavras\n",
      "Amostra: DORIL®\n",
      "(ácido acetilsalicílico + cafeína)\n",
      "\n",
      "Cosmed Indústria de Cosméticos e Medicamentos S.A.\n",
      "\n",
      "Comprimido\n",
      "\n",
      "500mg + 30mg\n",
      "\n",
      "\fI - IDENTIFICAÇÃO DO MEDICAMENTO:\n",
      "Doril®\n",
      "ácido acetilsalicílico + cafeína\n",
      "APRESENTAÇÕES\n",
      "Comprimido.\n",
      "Embalagens contendo 20 ou 150 comprimidos.\n",
      "VIA DE ADMINISTRAÇÃO: ORAL\n",
      "USO ADUL...\n",
      "\n",
      "----------------------------------------\n",
      "ETAPA: 1. Remover HTML\n",
      "----------------------------------------\n",
      "Tamanho: 13742 caracteres\n",
      "Palavras: 1955 palavras\n",
      "Amostra: DORIL®\n",
      "(ácido acetilsalicílico + cafeína)\n",
      "\n",
      "Cosmed Indústria de Cosméticos e Medicamentos S.A.\n",
      "\n",
      "Comprimido\n",
      "\n",
      "500mg + 30mg\n",
      "\n",
      "\fI - IDENTIFICAÇÃO DO MEDICAMENTO:\n",
      "Doril®\n",
      "ácido acetilsalicílico + cafeína\n",
      "APRESENTAÇÕES\n",
      "Comprimido.\n",
      "Embalagens contendo 20 ou 150 comprimidos.\n",
      "VIA DE ADMINISTRAÇÃO: ORAL\n",
      "USO ADUL...\n",
      "\n",
      "----------------------------------------\n",
      "ETAPA: 2. Remover URLs\n",
      "----------------------------------------\n",
      "Tamanho: 13742 caracteres\n",
      "Palavras: 1955 palavras\n",
      "Amostra: DORIL®\n",
      "(ácido acetilsalicílico + cafeína)\n",
      "\n",
      "Cosmed Indústria de Cosméticos e Medicamentos S.A.\n",
      "\n",
      "Comprimido\n",
      "\n",
      "500mg + 30mg\n",
      "\n",
      "\fI - IDENTIFICAÇÃO DO MEDICAMENTO:\n",
      "Doril®\n",
      "ácido acetilsalicílico + cafeína\n",
      "APRESENTAÇÕES\n",
      "Comprimido.\n",
      "Embalagens contendo 20 ou 150 comprimidos.\n",
      "VIA DE ADMINISTRAÇÃO: ORAL\n",
      "USO ADUL...\n",
      "\n",
      "----------------------------------------\n",
      "ETAPA: 3. Remover emojis\n",
      "----------------------------------------\n",
      "Tamanho: 13730 caracteres\n",
      "Palavras: 1955 palavras\n",
      "Amostra: DORIL\n",
      "(ácido acetilsalicílico + cafeína)\n",
      "\n",
      "Cosmed Indústria de Cosméticos e Medicamentos S.A.\n",
      "\n",
      "Comprimido\n",
      "\n",
      "500mg + 30mg\n",
      "\n",
      "\fI - IDENTIFICAÇÃO DO MEDICAMENTO:\n",
      "Doril\n",
      "ácido acetilsalicílico + cafeína\n",
      "APRESENTAÇÕES\n",
      "Comprimido.\n",
      "Embalagens contendo 20 ou 150 comprimidos.\n",
      "VIA DE ADMINISTRAÇÃO: ORAL\n",
      "USO ADULTO...\n",
      "\n",
      "----------------------------------------\n",
      "ETAPA: 4. Remover stopwords\n",
      "----------------------------------------\n",
      "Tamanho: 11613 caracteres\n",
      "Palavras: 1320 palavras\n",
      "Amostra: DORIL (ácido acetilsalicílico + cafeína) Cosmed Indústria Cosméticos Medicamentos S.A. Comprimido 500mg + 30mg I - IDENTIFICAÇÃO MEDICAMENTO: Doril ácido acetilsalicílico + cafeína APRESENTAÇÕES Comprimido. Embalagens contendo 20 150 comprimidos. VIA ADMINISTRAÇÃO: ORAL USO ADULTO COMPOSIÇÃO Cada co...\n",
      "\n",
      "----------------------------------------\n",
      "ETAPA: 5. Remover pontuação\n",
      "----------------------------------------\n",
      "Tamanho: 10952 caracteres\n",
      "Palavras: 1286 palavras\n",
      "Amostra: DORIL ácido acetilsalicílico  cafeína Cosmed Indústria Cosméticos Medicamentos SA Comprimido 500mg  30mg I  IDENTIFICAÇÃO MEDICAMENTO Doril ácido acetilsalicílico  cafeína APRESENTAÇÕES Comprimido Embalagens contendo 20 150 comprimidos VIA ADMINISTRAÇÃO ORAL USO ADULTO COMPOSIÇÃO Cada comprimido con...\n",
      "\n",
      "----------------------------------------\n",
      "ETAPA: 6. Remover caracteres especiais\n",
      "----------------------------------------\n",
      "Tamanho: 10884 caracteres\n",
      "Palavras: 1271 palavras\n",
      "Amostra: DORIL ácido acetilsalicílico  cafeína Cosmed Indústria Cosméticos Medicamentos SA Comprimido 500mg  30mg I  IDENTIFICAÇÃO MEDICAMENTO Doril ácido acetilsalicílico  cafeína APRESENTAÇÕES Comprimido Embalagens contendo 20 150 comprimidos VIA ADMINISTRAÇÃO ORAL USO ADULTO COMPOSIÇÃO Cada comprimido con...\n",
      "\n",
      "----------------------------------------\n",
      "ETAPA: 7. Remover espaços excedentes\n",
      "----------------------------------------\n",
      "Tamanho: 10835 caracteres\n",
      "Palavras: 1271 palavras\n",
      "Amostra: DORIL ácido acetilsalicílico cafeína Cosmed Indústria Cosméticos Medicamentos SA Comprimido 500mg 30mg I IDENTIFICAÇÃO MEDICAMENTO Doril ácido acetilsalicílico cafeína APRESENTAÇÕES Comprimido Embalagens contendo 20 150 comprimidos VIA ADMINISTRAÇÃO ORAL USO ADULTO COMPOSIÇÃO Cada comprimido contém ...\n",
      "\n",
      "----------------------------------------\n",
      "ETAPA: 8. Normalizar palavras de chat\n",
      "----------------------------------------\n",
      "Tamanho: 10835 caracteres\n",
      "Palavras: 1271 palavras\n",
      "Amostra: DORIL ácido acetilsalicílico cafeína Cosmed Indústria Cosméticos Medicamentos SA Comprimido 500mg 30mg I IDENTIFICAÇÃO MEDICAMENTO Doril ácido acetilsalicílico cafeína APRESENTAÇÕES Comprimido Embalagens contendo 20 150 comprimidos VIA ADMINISTRAÇÃO ORAL USO ADULTO COMPOSIÇÃO Cada comprimido contém ...\n",
      "\n",
      "----------------------------------------\n",
      "ETAPA: 9. Converter números\n",
      "----------------------------------------\n",
      "Tamanho: 11257 caracteres\n",
      "Palavras: 1332 palavras\n",
      "Amostra: DORIL ácido acetilsalicílico cafeína Cosmed Indústria Cosméticos Medicamentos SA Comprimido 50mg 3mg I IDENTIFICAÇÃO MEDICAMENTO Doril ácido acetilsalicílico cafeína APRESENTAÇÕES Comprimido Embalagens contendo vinte cento e cinquenta comprimidos VIA ADMINISTRAÇÃO ORAL USO ADULTO COMPOSIÇÃO Cada com...\n",
      "\n",
      "----------------------------------------\n",
      "ETAPA: 10. Converter para minúsculas\n",
      "----------------------------------------\n",
      "Tamanho: 11257 caracteres\n",
      "Palavras: 1332 palavras\n",
      "Amostra: doril ácido acetilsalicílico cafeína cosmed indústria cosméticos medicamentos sa comprimido 50mg 3mg i identificação medicamento doril ácido acetilsalicílico cafeína apresentações comprimido embalagens contendo vinte cento e cinquenta comprimidos via administração oral uso adulto composição cada com...\n",
      "\n",
      "----------------------------------------\n",
      "ETAPA: 11. Correção ortográfica\n",
      "----------------------------------------\n",
      "Tamanho: 11216 caracteres\n",
      "Palavras: 1332 palavras\n",
      "Amostra: doris ácido acetilsalicílico cafeína cosme indústria cosméticos medicamentos sa comprimido 50mg um i identificação medicamento doris ácido acetilsalicílico cafeína apresentações comprimido embalagens contendo vinte cento e cinquenta comprimidos via administração oral uso adulto composição cada compr...\n",
      "\n",
      "----------------------------------------\n",
      "ETAPA: 12. Stemização\n",
      "----------------------------------------\n",
      "Tamanho: 8317 caracteres\n",
      "Palavras: 1332 palavras\n",
      "Amostra: doril ácid acetilsalicíl cafeín cosm indústr cosmé medic sa comprim 50mg um i identific medic doril ácid acetilsalicíl cafeín apresent comprim embal cont vint cent e cinquent comprim via administr oral uso adult compos cad comprim contém ácid acetilsalicíl 50mg cafeín um excipi psp um comprim amid c...\n",
      "\n",
      "----------------------------------------\n",
      "ETAPA: 11. Correção ortográfica\n",
      "----------------------------------------\n",
      "Tamanho: 11216 caracteres\n",
      "Palavras: 1332 palavras\n",
      "Amostra: doris ácido acetilsalicílico cafeína cosme indústria cosméticos medicamentos sa comprimido 50mg um i identificação medicamento doris ácido acetilsalicílico cafeína apresentações comprimido embalagens contendo vinte cento e cinquenta comprimidos via administração oral uso adulto composição cada compr...\n",
      "\n",
      "----------------------------------------\n",
      "ETAPA: 12. Stemização\n",
      "----------------------------------------\n",
      "Tamanho: 8317 caracteres\n",
      "Palavras: 1332 palavras\n",
      "Amostra: doril ácid acetilsalicíl cafeín cosm indústr cosmé medic sa comprim 50mg um i identific medic doril ácid acetilsalicíl cafeín apresent comprim embal cont vint cent e cinquent comprim via administr oral uso adult compos cad comprim contém ácid acetilsalicíl 50mg cafeín um excipi psp um comprim amid c...\n",
      "\n",
      "----------------------------------------\n",
      "ETAPA: 13. Lematização\n",
      "----------------------------------------\n",
      "Tamanho: 9136 caracteres\n",
      "Palavras: 1361 palavras\n",
      "Amostra: doril ácido acetilsalicíl Cafeín cosm indústr Cosmé médico sa comprimido 50 um i identific médico doril ácido acetilsalicíl Cafeín apresentar comprimido embal cont vinte cent e cinquenta comprimido ver administrar oral uso adulto compo cada comprimido contémr ácido acetilsalicíl 50 Cafeín um excipir...\n",
      "\n",
      "----------------------------------------\n",
      "ETAPA: 13. Lematização\n",
      "----------------------------------------\n",
      "Tamanho: 9136 caracteres\n",
      "Palavras: 1361 palavras\n",
      "Amostra: doril ácido acetilsalicíl Cafeín cosm indústr Cosmé médico sa comprimido 50 um i identific médico doril ácido acetilsalicíl Cafeín apresentar comprimido embal cont vinte cent e cinquenta comprimido ver administrar oral uso adulto compo cada comprimido contémr ácido acetilsalicíl 50 Cafeín um excipir...\n"
     ]
    }
   ],
   "source": [
    "# Aplicando pré-processamento na BULA DO DORIL\n",
    "resultados_doril = apply_preprocessing_steps(texto_doril, \"Bula do Doril\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6e9d9ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "PRÉ-PROCESSAMENTO: JORNAL A TRIBUNA\n",
      "============================================================\n",
      "\n",
      "----------------------------------------\n",
      "ETAPA: Original\n",
      "----------------------------------------\n",
      "Tamanho: 2634 caracteres\n",
      "Palavras: 413 palavras\n",
      "Amostra: VITÓRIA-ES | DOMINGO, 14 DE JANEIRO DE 2018 | ANO LXXIX | Nº 26.236 | FUNDADO EM 22/09/1938 | EDIÇÃO DE 72 PÁGINAS Vo c ê conhece bem seus amigos? >AT 2 THIAGO COUTINHO/AT THIAGO COUTINHO/AT R$ 3,50 DEMAIS CIDADES R$ 3 ,0 0 GRANDE VITÓRIA AS S I N E 3323 -6333 Transexuais querem fazer parte da cota ...\n",
      "\n",
      "----------------------------------------\n",
      "ETAPA: 1. Remover HTML\n",
      "----------------------------------------\n",
      "Tamanho: 2634 caracteres\n",
      "Palavras: 413 palavras\n",
      "Amostra: VITÓRIA-ES | DOMINGO, 14 DE JANEIRO DE 2018 | ANO LXXIX | Nº 26.236 | FUNDADO EM 22/09/1938 | EDIÇÃO DE 72 PÁGINAS Vo c ê conhece bem seus amigos? >AT 2 THIAGO COUTINHO/AT THIAGO COUTINHO/AT R$ 3,50 DEMAIS CIDADES R$ 3 ,0 0 GRANDE VITÓRIA AS S I N E 3323 -6333 Transexuais querem fazer parte da cota ...\n",
      "\n",
      "----------------------------------------\n",
      "ETAPA: 2. Remover URLs\n",
      "----------------------------------------\n",
      "Tamanho: 2590 caracteres\n",
      "Palavras: 412 palavras\n",
      "Amostra: VITÓRIA-ES | DOMINGO, 14 DE JANEIRO DE 2018 | ANO LXXIX | Nº 26.236 | FUNDADO EM 22/09/1938 | EDIÇÃO DE 72 PÁGINAS Vo c ê conhece bem seus amigos? >AT 2 THIAGO COUTINHO/AT THIAGO COUTINHO/AT R$ 3,50 DEMAIS CIDADES R$ 3 ,0 0 GRANDE VITÓRIA AS S I N E 3323 -6333 Transexuais querem fazer parte da cota ...\n",
      "\n",
      "----------------------------------------\n",
      "ETAPA: 3. Remover emojis\n",
      "----------------------------------------\n",
      "Tamanho: 2583 caracteres\n",
      "Palavras: 411 palavras\n",
      "Amostra: VITÓRIA-ES | DOMINGO, 14 DE JANEIRO DE 2018 | ANO LXXIX | Nº 26.236 | FUNDADO EM 22/09/1938 | EDIÇÃO DE 72 PÁGINAS Vo c ê conhece bem seus amigos? >AT 2 THIAGO COUTINHO/AT THIAGO COUTINHO/AT R$ 3,50 DEMAIS CIDADES R$ 3 ,0 0 GRANDE VITÓRIA AS S I N E 3323 -6333 Transexuais querem fazer parte da cota ...\n",
      "\n",
      "----------------------------------------\n",
      "ETAPA: 4. Remover stopwords\n",
      "----------------------------------------\n",
      "Tamanho: 2195 caracteres\n",
      "Palavras: 309 palavras\n",
      "Amostra: VITÓRIA-ES | DOMINGO, 14 JANEIRO 2018 | ANO LXXIX | Nº 26.236 | FUNDADO 22/09/1938 | EDIÇÃO 72 PÁGINAS Vo c ê conhece bem amigos? >AT 2 THIAGO COUTINHO/AT THIAGO COUTINHO/AT R$ 3,50 DEMAIS CIDADES R$ 3 ,0 0 GRANDE VITÓRIA S I N 3323 -6333 Transexuais querem fazer parte cota feminina próximas eleiçõe...\n",
      "\n",
      "----------------------------------------\n",
      "ETAPA: 5. Remover pontuação\n",
      "----------------------------------------\n",
      "Tamanho: 2087 caracteres\n",
      "Palavras: 301 palavras\n",
      "Amostra: VITÓRIAES  DOMINGO 14 JANEIRO 2018  ANO LXXIX  Nº 26236  FUNDADO 22091938  EDIÇÃO 72 PÁGINAS Vo c ê conhece bem amigos AT 2 THIAGO COUTINHOAT THIAGO COUTINHOAT R 350 DEMAIS CIDADES R 3 0 0 GRANDE VITÓRIA S I N 3323 6333 Transexuais querem fazer parte cota feminina próximas eleições 32 R efúgios ro m...\n",
      "\n",
      "----------------------------------------\n",
      "ETAPA: 6. Remover caracteres especiais\n",
      "----------------------------------------\n",
      "Tamanho: 1905 caracteres\n",
      "Palavras: 298 palavras\n",
      "Amostra: VITÓRIAES  DOMINGO 14 JANEIRO 2018  ANO LXXIX  N 26236  FUNDADO 22091938  EDIÇÃO 72 PÁGINAS Vo c ê conhece bem amigos AT 2 THIAGO COUTINHOAT THIAGO COUTINHOAT R 350 DEMAIS CIDADES R 3 0 0 GRANDE VITÓRIA S I N 3323 633 Transexuais querem fazer parte cota feminina próximas eleições 32 R efúgios ro m â...\n",
      "\n",
      "----------------------------------------\n",
      "ETAPA: 7. Remover espaços excedentes\n",
      "----------------------------------------\n",
      "Tamanho: 1894 caracteres\n",
      "Palavras: 298 palavras\n",
      "Amostra: VITÓRIAES DOMINGO 14 JANEIRO 2018 ANO LXXIX N 26236 FUNDADO 22091938 EDIÇÃO 72 PÁGINAS Vo c ê conhece bem amigos AT 2 THIAGO COUTINHOAT THIAGO COUTINHOAT R 350 DEMAIS CIDADES R 3 0 0 GRANDE VITÓRIA S I N 3323 633 Transexuais querem fazer parte cota feminina próximas eleições 32 R efúgios ro m â n t ...\n",
      "\n",
      "----------------------------------------\n",
      "ETAPA: 8. Normalizar palavras de chat\n",
      "----------------------------------------\n",
      "Tamanho: 1907 caracteres\n",
      "Palavras: 298 palavras\n",
      "Amostra: VITÓRIAES DOMINGO 14 JANEIRO 2018 ANO LXXIX N 26236 FUNDADO 22091938 EDIÇÃO 72 PÁGINAS Vo c ê conhece bem amigos AT 2 THIAGO COUTINHOAT THIAGO COUTINHOAT R 350 DEMAIS CIDADES R 3 0 0 GRANDE VITÓRIA S I N 3323 633 Transexuais querem fazer parte cota feminina próximas eleições 32 R efúgios ro m â n t ...\n",
      "\n",
      "----------------------------------------\n",
      "ETAPA: 9. Converter números\n",
      "----------------------------------------\n",
      "Tamanho: 2278 caracteres\n",
      "Palavras: 358 palavras\n",
      "Amostra: VITÓRIAES DOMINGO catorze JANEIRO dois mil e dezoito ANO LXXIX N vinte e seis mil duzentos e trinta e seis FUNDADO vinte e dois nove mil novecentos e trinta e oito EDIÇÃO setenta e dois PÁGINAS Vo c ê conhece bem amigos AT dois THIAGO COUTINHOAT THIAGO COUTINHOAT R trezentos e cinquenta DEMAIS CIDAD...\n",
      "\n",
      "----------------------------------------\n",
      "ETAPA: 10. Converter para minúsculas\n",
      "----------------------------------------\n",
      "Tamanho: 2278 caracteres\n",
      "Palavras: 358 palavras\n",
      "Amostra: vitóriaes domingo catorze janeiro dois mil e dezoito ano lxxix n vinte e seis mil duzentos e trinta e seis fundado vinte e dois nove mil novecentos e trinta e oito edição setenta e dois páginas vo c ê conhece bem amigos at dois thiago coutinhoat thiago coutinhoat r trezentos e cinquenta demais cidad...\n",
      "\n",
      "----------------------------------------\n",
      "ETAPA: 11. Correção ortográfica\n",
      "----------------------------------------\n",
      "Tamanho: 2108 caracteres\n",
      "Palavras: 358 palavras\n",
      "Amostra: vitórias domingo catorze janeiro dois mil e dezoito ano xxi n vinte e seis mil duzentos e trinta e seis fundado vinte e dois nove mil novecentos e trinta e oito edição setenta e dois páginas vo c ê conhece bem amigos at dois tiago coutinho tiago coutinho r trezentos e cinquenta demais cidades r três...\n",
      "\n",
      "----------------------------------------\n",
      "ETAPA: 12. Stemização\n",
      "----------------------------------------\n",
      "Tamanho: 1710 caracteres\n",
      "Palavras: 358 palavras\n",
      "Amostra: vitór doming catorz jan doi mil e dezoit ano xxi n vint e seil mil duzent e trint e seil fund vint e doi nov mil novecent e trint e oit ediç setent e doi págin vo c ê conhec bem amig at doi tiag cout tiag cout r trezent e cinquent demal cidad r trê zer zer grand vitór s i n trê mil trezent e vint e ...\n",
      "\n",
      "----------------------------------------\n",
      "ETAPA: 11. Correção ortográfica\n",
      "----------------------------------------\n",
      "Tamanho: 2108 caracteres\n",
      "Palavras: 358 palavras\n",
      "Amostra: vitórias domingo catorze janeiro dois mil e dezoito ano xxi n vinte e seis mil duzentos e trinta e seis fundado vinte e dois nove mil novecentos e trinta e oito edição setenta e dois páginas vo c ê conhece bem amigos at dois tiago coutinho tiago coutinho r trezentos e cinquenta demais cidades r três...\n",
      "\n",
      "----------------------------------------\n",
      "ETAPA: 12. Stemização\n",
      "----------------------------------------\n",
      "Tamanho: 1710 caracteres\n",
      "Palavras: 358 palavras\n",
      "Amostra: vitór doming catorz jan doi mil e dezoit ano xxi n vint e seil mil duzent e trint e seil fund vint e doi nov mil novecent e trint e oit ediç setent e doi págin vo c ê conhec bem amig at doi tiag cout tiag cout r trezent e cinquent demal cidad r trê zer zer grand vitór s i n trê mil trezent e vint e ...\n",
      "\n",
      "----------------------------------------\n",
      "ETAPA: 13. Lematização\n",
      "----------------------------------------\n",
      "Tamanho: 1899 caracteres\n",
      "Palavras: 365 palavras\n",
      "Amostra: vitór doming catorze jan de oi mil e dezoit ano xxi n vinte e seis mil duzent e trinta e seis fundar vinte e de oi nove mil novecent e trinta e oito edição Setent e de oi página vo c ê conhecer bem amigo at de oi tiag cout tiag cout r trezent e cinquenta demal cidade r três zer zer grande vitór s i ...\n",
      "\n",
      "----------------------------------------\n",
      "ETAPA: 13. Lematização\n",
      "----------------------------------------\n",
      "Tamanho: 1899 caracteres\n",
      "Palavras: 365 palavras\n",
      "Amostra: vitór doming catorze jan de oi mil e dezoit ano xxi n vinte e seis mil duzent e trinta e seis fundar vinte e de oi nove mil novecent e trinta e oito edição Setent e de oi página vo c ê conhecer bem amigo at de oi tiag cout tiag cout r trezent e cinquenta demal cidade r três zer zer grande vitór s i ...\n"
     ]
    }
   ],
   "source": [
    "# Aplicando pré-processamento no JORNAL A TRIBUNA\n",
    "resultados_jornal = apply_preprocessing_steps(texto_jornal, \"Jornal A Tribuna\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3135cd93",
   "metadata": {},
   "source": [
    "## Comparação Final: Original vs Processado\n",
    "\n",
    "Vamos comparar o texto original com o texto final após todas as transformações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9c08e25f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "COMPARAÇÃO FINAL: BULA DO DORIL\n",
      "================================================================================\n",
      "\n",
      " ESTATÍSTICAS:\n",
      "   Original: 13742 caracteres, 1955 palavras\n",
      "   Final: 9136 caracteres, 1361 palavras\n",
      "   Redução: 33.5% dos caracteres\n",
      "\n",
      " TEXTO ORIGINAL (primeiros 500 caracteres):\n",
      "   DORIL®\n",
      "(ácido acetilsalicílico + cafeína)\n",
      "\n",
      "Cosmed Indústria de Cosméticos e Medicamentos S.A.\n",
      "\n",
      "Comprimido\n",
      "\n",
      "500mg + 30mg\n",
      "\n",
      "\fI - IDENTIFICAÇÃO DO MEDICAMENTO:\n",
      "Doril®\n",
      "ácido acetilsalicílico + cafeína\n",
      "APRESENTAÇÕES\n",
      "Comprimido.\n",
      "Embalagens contendo 20 ou 150 comprimidos.\n",
      "VIA DE ADMINISTRAÇÃO: ORAL\n",
      "USO ADULTO\n",
      "COMPOSIÇÃO\n",
      "Cada comprimido contém:\n",
      "ácido acetilsalicílico …………………………………………………….................................... 500mg\n",
      "cafeína ………………………………….................……………………………….…...…............ 30mg\n",
      "ex...\n",
      "\n",
      "🔧 TEXTO FINAL (primeiros 500 caracteres):\n",
      "   doril ácido acetilsalicíl Cafeín cosm indústr Cosmé médico sa comprimido 50 um i identific médico doril ácido acetilsalicíl Cafeín apresentar comprimido embal cont vinte cent e cinquenta comprimido ver administrar oral uso adulto compo cada comprimido contémr ácido acetilsalicíl 50 Cafeín um excipir psp um comprimido amido cor vermelho eritrosin n três doril comprimido bula paciente um ii inforr paciente um médico indicado doril indicado analgésico antipirético especial tratar dor redução febre ...\n",
      "\n",
      "================================================================================\n",
      "COMPARAÇÃO FINAL: JORNAL A TRIBUNA\n",
      "================================================================================\n",
      "\n",
      " ESTATÍSTICAS:\n",
      "   Original: 2634 caracteres, 413 palavras\n",
      "   Final: 1899 caracteres, 365 palavras\n",
      "   Redução: 27.9% dos caracteres\n",
      "\n",
      " TEXTO ORIGINAL (primeiros 500 caracteres):\n",
      "   VITÓRIA-ES | DOMINGO, 14 DE JANEIRO DE 2018 | ANO LXXIX | Nº 26.236 | FUNDADO EM 22/09/1938 | EDIÇÃO DE 72 PÁGINAS Vo c ê conhece bem seus amigos? >AT 2 THIAGO COUTINHO/AT THIAGO COUTINHO/AT R$ 3,50 DEMAIS CIDADES R$ 3 ,0 0 GRANDE VITÓRIA AS S I N E 3323 -6333 Transexuais querem fazer parte da cota feminina nas próximas eleições >32 R efúgios ro m â n t i c o s no Estado >14 e 15 Cupom para concorrer a R$ 500 em compras >13 PPPaaaiiisss   pppeeedddeeemmm   aaajjjuuudddaaa   aaa mmmééédddiiicccoo...\n",
      "\n",
      "🔧 TEXTO FINAL (primeiros 500 caracteres):\n",
      "   vitór doming catorze jan de oi mil e dezoit ano xxi n vinte e seis mil duzent e trinta e seis fundar vinte e de oi nove mil novecent e trinta e oito edição Setent e de oi página vo c ê conhecer bem amigo at de oi tiag cout tiag cout r trezent e cinquenta demal cidade r três zer zer grande vitór s i n três mil trezent e vinte e três seiscent e trinta e três transex querer fazer parte cot feminino próximo ele trinta e de oi r refúgio ro m â n t i c s estar catorze quinze com concorrer r quinhent c...\n"
     ]
    }
   ],
   "source": [
    "def show_final_comparison(results, text_name):\n",
    "    \"\"\"Mostra comparação entre texto original e final\"\"\"\n",
    "    \n",
    "    original = results[\"Original\"]\n",
    "    final = results[\"13. Lematização\"]\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"COMPARAÇÃO FINAL: {text_name.upper()}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    print(f\"\\n ESTATÍSTICAS:\")\n",
    "    print(f\"   Original: {len(original)} caracteres, {len(original.split())} palavras\")\n",
    "    print(f\"   Final: {len(final)} caracteres, {len(final.split())} palavras\")\n",
    "    print(f\"   Redução: {((len(original) - len(final)) / len(original) * 100):.1f}% dos caracteres\")\n",
    "    \n",
    "    print(f\"\\n TEXTO ORIGINAL (primeiros 500 caracteres):\")\n",
    "    print(f\"   {original[:500]}...\")\n",
    "    \n",
    "    print(f\"\\n🔧 TEXTO FINAL (primeiros 500 caracteres):\")\n",
    "    print(f\"   {final[:500]}...\")\n",
    "    \n",
    "    return original, final\n",
    "\n",
    "# Comparações finais\n",
    "original_doril, final_doril = show_final_comparison(resultados_doril, \"Bula do Doril\")\n",
    "original_jornal, final_jornal = show_final_comparison(resultados_jornal, \"Jornal A Tribuna\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6f6dc8",
   "metadata": {},
   "source": [
    "## Salvando os Resultados\n",
    "\n",
    "Vamos salvar os textos processados em arquivos para referência futura."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2937411b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Salvando textos processados formatados...\n",
      " Resultados salvos em:\n",
      "    TEXTOS FORMATADOS:\n",
      "      - doril_processado.txt\n",
      "      - jornal_processado.txt\n",
      "    LOG:\n",
      "      - log_preprocessamento.txt\n",
      "\n",
      " Pré-processamento concluído com textos formatados!\n"
     ]
    }
   ],
   "source": [
    "# Função para formatar texto de forma legível\n",
    "def formatar_texto_legivel(texto, palavras_por_linha=10):\n",
    "    \"\"\"Formata o texto quebrando em linhas com número limitado de palavras\"\"\"\n",
    "    palavras = texto.split()\n",
    "    linhas = []\n",
    "    linha_atual = []\n",
    "    \n",
    "    for palavra in palavras:\n",
    "        linha_atual.append(palavra)\n",
    "        if len(linha_atual) >= palavras_por_linha:\n",
    "            linhas.append(' '.join(linha_atual))\n",
    "            linha_atual = []\n",
    "    \n",
    "    # Adiciona a última linha se sobrou algo\n",
    "    if linha_atual:\n",
    "        linhas.append(' '.join(linha_atual))\n",
    "    \n",
    "    return '\\n'.join(linhas)\n",
    "\n",
    "# Salvando os resultados finais FORMATADOS EM LINHAS\n",
    "print(\" Salvando textos processados formatados...\")\n",
    "\n",
    "# Formata os textos\n",
    "doril_formatado = formatar_texto_legivel(final_doril, palavras_por_linha=10)\n",
    "jornal_formatado = formatar_texto_legivel(final_jornal, palavras_por_linha=10)\n",
    "\n",
    "# Salva apenas as versões formatadas em linhas\n",
    "with open('doril_processado.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(\"=== BULA DORIL - TEXTO PROCESSADO (FORMATADO) ===\\n\\n\")\n",
    "    f.write(doril_formatado)\n",
    "\n",
    "with open('jornal_processado.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(\"=== JORNAL A TRIBUNA - TEXTO PROCESSADO (FORMATADO) ===\\n\\n\")\n",
    "    f.write(jornal_formatado)\n",
    "\n",
    "# Salvando log detalhado de todas as etapas\n",
    "with open('log_preprocessamento.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(\"RELATÓRIO DE PRÉ-PROCESSAMENTO DE TEXTOS\\n\")\n",
    "    f.write(\"=\" * 60 + \"\\n\\n\")\n",
    "    \n",
    "    for texto_nome, resultados in [(\"BULA DORIL\", resultados_doril), (\"JORNAL A TRIBUNA\", resultados_jornal)]:\n",
    "        f.write(f\"\\n {texto_nome}\\n\")\n",
    "        f.write(\"-\" * 40 + \"\\n\")\n",
    "        \n",
    "        for etapa, conteudo in resultados.items():\n",
    "            f.write(f\"\\n {etapa}:\\n\")\n",
    "            f.write(f\"   Caracteres: {len(conteudo)}\\n\")\n",
    "            f.write(f\"   Palavras: {len(conteudo.split())}\\n\")\n",
    "            \n",
    "            # Formata uma amostra para o log\n",
    "            if len(conteudo) > 200:\n",
    "                amostra_formatada = formatar_texto_legivel(conteudo[:200], palavras_por_linha=8)\n",
    "                f.write(f\"   Amostra:\\n\")\n",
    "                for linha in amostra_formatada.split('\\n')[:3]:\n",
    "                    f.write(f\"      {linha}\\n\")\n",
    "                f.write(f\"      ...\\n\")\n",
    "            else:\n",
    "                amostra_formatada = formatar_texto_legivel(conteudo, palavras_por_linha=8)\n",
    "                f.write(f\"   Conteúdo:\\n\")\n",
    "                for linha in amostra_formatada.split('\\n'):\n",
    "                    f.write(f\"      {linha}\\n\")\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "print(\" Resultados salvos em:\")\n",
    "print(\"    TEXTOS FORMATADOS:\")\n",
    "print(\"      - doril_processado.txt\")\n",
    "print(\"      - jornal_processado.txt\")\n",
    "print(\"    LOG:\")\n",
    "print(\"      - log_preprocessamento.txt\")\n",
    "print(\"\\n Pré-processamento concluído com textos formatados!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dfd81166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TESTE DE CONVERSÃO DOS NÚMEROS PROBLEMÁTICOS ===\n",
      "Números originais: 50 500 30 65 8 700 2 4 1 610824260020\n",
      "Após conversão: cinquenta quinhentos trinta sessenta e cinco oito setecentos dois quatro um seiscentos e dez mil oitocentos e vinte e quatro milhões duzentos e sessenta mil vinte\n",
      "\n",
      "=== TESTE INDIVIDUAL ===\n",
      "50 -> cinquenta\n",
      "500 -> quinhentos\n",
      "30 -> trinta\n",
      "65 -> sessenta e cinco\n",
      "700 -> setecentos\n",
      "\n",
      "✅ Teste de conversão concluído!\n"
     ]
    }
   ],
   "source": [
    "# Teste específico para números que ainda estão no Doril\n",
    "print(\"=== TESTE DE CONVERSÃO DOS NÚMEROS PROBLEMÁTICOS ===\")\n",
    "\n",
    "# Simula os números que ainda estão presentes no arquivo\n",
    "numeros_teste = \"50 500 30 65 8 700 2 4 1 610824260020\"\n",
    "print(f\"Números originais: {numeros_teste}\")\n",
    "\n",
    "# Aplica apenas a função de conversão de números\n",
    "resultado_conversao = step_9_convert_numbers_to_words(numeros_teste)\n",
    "print(f\"Após conversão: {resultado_conversao}\")\n",
    "\n",
    "print(\"\\n=== TESTE INDIVIDUAL ===\")\n",
    "for num in [\"50\", \"500\", \"30\", \"65\", \"700\"]:\n",
    "    convertido = step_9_convert_numbers_to_words(num)\n",
    "    print(f\"{num} -> {convertido}\")\n",
    "\n",
    "print(\"\\n✅ Teste de conversão concluído!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0dc65a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CORRIGINDO NÚMEROS NO ARQUIVO DORIL_PROCESSADO.TXT ===\n",
      "Arquivo carregado: 9187 caracteres\n",
      "Números encontrados: {'50'}\n",
      "Aplicando correção de números...\n",
      "Números após correção: NENHUM! ✅\n",
      " Arquivo doril_processado.txt atualizado com números convertidos!\n",
      "\n",
      "=== AMOSTRA DO RESULTADO ===\n",
      "=== BULA DORIL - TEXTO PROCESSADO (FORMATADO) ===\n",
      "\n",
      "doril ácido acetilsalicíl Cafeín cosm indústr Cosmé médico sa comprimido\n",
      "cinquenta um i identific médico doril ácido acetilsalicíl Cafeín apresentar\n",
      "comprimido embal cont vinte cent e cinquenta comprimido ver administrar\n",
      "oral uso adulto compo cada comprimido contémr ácido acetilsalicíl cinquenta\n",
      "Cafeín um excipir psp um comprimido amido cor vermelho eritrosin\n",
      "n três doril comprimido bula paciente um ii inforr paciente\n",
      "um médico indicado doril in...\n"
     ]
    }
   ],
   "source": [
    "# Correção direta dos números no arquivo do Doril\n",
    "print(\"=== CORRIGINDO NÚMEROS NO ARQUIVO DORIL_PROCESSADO.TXT ===\")\n",
    "\n",
    "# Lê o arquivo atual\n",
    "with open('doril_processado.txt', 'r', encoding='utf-8') as f:\n",
    "    conteudo_doril = f.read()\n",
    "\n",
    "print(f\"Arquivo carregado: {len(conteudo_doril)} caracteres\")\n",
    "\n",
    "# Identifica números presentes\n",
    "import re\n",
    "numeros_encontrados = re.findall(r'\\b\\d+\\b', conteudo_doril)\n",
    "print(f\"Números encontrados: {set(numeros_encontrados)}\")\n",
    "\n",
    "# Remove o cabeçalho e aplica correção apenas no conteúdo\n",
    "linhas = conteudo_doril.split('\\n')\n",
    "cabecalho = linhas[0] + '\\n\\n'  # Preserva cabeçalho\n",
    "conteudo_apenas = '\\n'.join(linhas[2:])  # Pega só o conteúdo\n",
    "\n",
    "print(\"Aplicando correção de números...\")\n",
    "conteudo_corrigido = step_9_convert_numbers_to_words(conteudo_apenas)\n",
    "\n",
    "# Verifica se a correção funcionou\n",
    "numeros_apos_correcao = re.findall(r'\\b\\d+\\b', conteudo_corrigido)\n",
    "print(f\"Números após correção: {set(numeros_apos_correcao) if numeros_apos_correcao else 'NENHUM! ✅'}\")\n",
    "\n",
    "# Salva o arquivo corrigido\n",
    "arquivo_corrigido = cabecalho + conteudo_corrigido\n",
    "\n",
    "with open('doril_processado.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(arquivo_corrigido)\n",
    "\n",
    "print(\" Arquivo doril_processado.txt atualizado com números convertidos!\")\n",
    "\n",
    "# Mostra uma amostra do resultado\n",
    "print(\"\\n=== AMOSTRA DO RESULTADO ===\")\n",
    "print(arquivo_corrigido[:500] + \"...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
